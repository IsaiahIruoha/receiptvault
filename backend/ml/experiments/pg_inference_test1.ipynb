{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "!pip install -q datasets lightning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e444dc36afc4491af5609ed1577e782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "    \n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoTokenizer, PaliGemmaForConditionalGeneration, PaliGemmaProcessor, AutoProcessor\n",
    "\n",
    "PROMPT = \"extract JSON.\"\n",
    "img_path = \"1.jpg\"\n",
    "input_image = Image.open(img_path)\n",
    "MAX_LENGTH = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2366c0866dfe4331a87077d8814b1b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4355dc50026144afb2a39c7ef52b5621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ff442d7acb4769826301fce5ce5646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf4cd1882c34c8e9ee59088f25f9f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43efe0082d344149a372c85ba4a6e1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887b7e1a045f49e0ba68ee0b505e22fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65da9a5d1ec4789a7a99d477d400139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"nielsr/paligemma-cord-demo\"\n",
    "processor_id = \"google/paligemma-3b-pt-224\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\n",
    "processor = AutoProcessor.from_pretrained(processor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 261])\n",
      "attention_mask torch.Size([1, 261])\n",
      "pixel_values torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(text=PROMPT, images=input_image, return_tensors=\"pt\")\n",
    "for k,v in inputs.items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extract JSON.\\n<s_total_price>440.00</s_total_price><s_cashprice>440.00</s_cashprice><s_creditcardprice>0.00</s_creditcardprice><s_changeprice>0.00</s_changeprice><s_menu><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model.generate(**inputs, max_new_tokens=MAX_LENGTH)\n",
    "\n",
    "\n",
    "# Turn each predicted Token ID back into a string using decode method\n",
    "#We chop off the prompt, which consists of image tokens and our text prompt\n",
    "image_token_index = model.config.image_token_index\n",
    "num_image_tokens = len(generated_ids[generated_ids==image_token_index])\n",
    "num_text_tokens = len(processor.tokenizer.encode(PROMPT))\n",
    "num_prompt_tokens = num_image_tokens = num_text_tokens + 2\n",
    "generated_text = processor.batch_decode(generated_ids[:, num_prompt_tokens:], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extract JSON.\\n<s_total_price>440.00</s_total_price><s_cashprice>440.00</s_cashprice><s_creditcardprice>0.00</s_creditcardprice><s_changeprice>0.00</s_changeprice><s_menu><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</s_nm><s_cnt>1</s_cnt><sep/><s_unitprice>2.99</s_unitprice><s_price>2.99</s_price><s_nm>E-CARROTS, CHIMICHURRI, 10 OZ</'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# let's turn that into JSON\n",
    "def token2json(tokens, is_inner_value=False, added_vocab=None):\n",
    "        \"\"\"\n",
    "        Convert a (generated) token sequence into an ordered JSON format.\n",
    "        \"\"\"\n",
    "        if added_vocab is None:\n",
    "            added_vocab = processor.tokenizer.get_added_vocab()\n",
    "\n",
    "        output = {}\n",
    "\n",
    "        while tokens:\n",
    "            start_token = re.search(r\"<s_(.*?)>\", tokens, re.IGNORECASE)\n",
    "            if start_token is None:\n",
    "                break\n",
    "            key = start_token.group(1)\n",
    "            key_escaped = re.escape(key)\n",
    "\n",
    "            end_token = re.search(rf\"</s_{key_escaped}>\", tokens, re.IGNORECASE)\n",
    "            start_token = start_token.group()\n",
    "            if end_token is None:\n",
    "                tokens = tokens.replace(start_token, \"\")\n",
    "            else:\n",
    "                end_token = end_token.group()\n",
    "                start_token_escaped = re.escape(start_token)\n",
    "                end_token_escaped = re.escape(end_token)\n",
    "                content = re.search(\n",
    "                    f\"{start_token_escaped}(.*?){end_token_escaped}\", tokens, re.IGNORECASE | re.DOTALL\n",
    "                )\n",
    "                if content is not None:\n",
    "                    content = content.group(1).strip()\n",
    "                    if r\"<s_\" in content and r\"</s_\" in content:  # non-leaf node\n",
    "                        value = token2json(content, is_inner_value=True, added_vocab=added_vocab)\n",
    "                        if value:\n",
    "                            if len(value) == 1:\n",
    "                                value = value[0]\n",
    "                            output[key] = value\n",
    "                    else:  # leaf nodes\n",
    "                        output[key] = []\n",
    "                        for leaf in content.split(r\"<sep/>\"):\n",
    "                            leaf = leaf.strip()\n",
    "                            if leaf in added_vocab and leaf[0] == \"<\" and leaf[-2:] == \"/>\":\n",
    "                                leaf = leaf[1:-2]  # for categorical special tokens\n",
    "                            output[key].append(leaf)\n",
    "                        if len(output[key]) == 1:\n",
    "                            output[key] = output[key][0]\n",
    "\n",
    "                tokens = tokens[tokens.find(end_token) + len(end_token) :].strip()\n",
    "                if tokens[:6] == r\"<sep/>\":  # non-leaf nodes\n",
    "                    return [output] + token2json(tokens[6:], is_inner_value=True, added_vocab=added_vocab)\n",
    "\n",
    "        if len(output):\n",
    "            return [output] if is_inner_value else output\n",
    "        else:\n",
    "            return [] if is_inner_value else {\"text_sequence\": tokens}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'total_price': '440.00', 'cashprice': '440.00', 'creditcardprice': '0.00', 'changeprice': '0.00', 'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99', 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ', 'cnt': '1'}, {'unitprice': '2.99', 'price': '2.99'}]\n"
     ]
    }
   ],
   "source": [
    "generated_json = token2json(generated_text[0])\n",
    "print(generated_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unitprice': '2.99',\n",
       " 'price': '2.99',\n",
       " 'nm': 'E-CARROTS, CHIMICHURRI, 10 OZ',\n",
       " 'cnt': '1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_json[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
