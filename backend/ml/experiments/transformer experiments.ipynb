{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers for OCR Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "# !pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0\n",
      "CUDA available: False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check the PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c45ba1f6d14e6492793e31635caf19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--microsoft--trocr-small-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261c354a84704a4e88d0f6e16ce0f207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6726704ca7b246528f560e78a7f7ef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15916\\658043795.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrOCRProcessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'microsoft/trocr-small-printed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m model = VisionEncoderDecoderModel.from_pretrained(\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;34m'microsoft/trocr-small-printed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m ).to(device)\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2956\u001b[0m                     \u001b[1;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m                 )\n\u001b[1;32m-> 2958\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m                     \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                     )\n\u001b[1;32m-> 1160\u001b[1;33m                 return t.to(\n\u001b[0m\u001b[0;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# def download_and_unzip(url, save_path):\n",
    "#     print(f\"Downloading and extracting assets....\", end=\"\")\n",
    "\n",
    "#     # Downloading zip file using urllib package\n",
    "#     urlretrieve(url, save_path)\n",
    "\n",
    "#     try: \n",
    "#         # Extracting zip file using the zipfile package\n",
    "#         with ZipFile(save_path) as z: \n",
    "#             # Extract ZIP file contents in the same directory\n",
    "#             z.extractall(os.path.save_path[0])\n",
    "        \n",
    "#         print(\"Done\")\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(\"\\nInvalid file.\", e)\n",
    "\n",
    "# URL = r\"https://www.dropbox.com/scl/fi/news/images.zip?rlkey=54flzvhh9xxh45czb1c8n3fp3&dl=1\"\n",
    "# asset_zip_path = os.path.join(os.getcwd(), \"images.zip\")\n",
    "# # Download if assest ZIP does not exists.\n",
    "# if not os.path.exists(asset_zip_path):\n",
    "#     download_and_unzip(URL, asset_zip_path)\n",
    "\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "    :param image_path : String, path to the input image.\n",
    "\n",
    "    Returns: \n",
    "        image : PIL Image.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image\n",
    "def ocr(image, processor, model):\n",
    "    \"\"\"+\n",
    "    :param image: PIL Image. \n",
    "    :param processor: Huggingface OCR processor.\n",
    "    :param model: HUggingface OCR model\n",
    "\n",
    "    Returns: \n",
    "        generated_text: the OCR'd text string.\n",
    "    \"\"\"\n",
    "    # We can directly perform OCR on cropped images.\n",
    "    pixel_values = processor(image, return_tensors='pt').pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_text\n",
    "\n",
    "def eval_new_data(data_path=None, num_samples=4, model=None, processor=None):\n",
    "    image_paths = glob.glob(data_path)\n",
    "    for i, image_path in tqdm(enumerate(image_paths), total=len(image_paths)):\n",
    "        if i == num_samples:\n",
    "            break\n",
    "        image = read_image(image_path)\n",
    "        text = ocr(image, processor, model)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-printed')\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    'microsoft/trocr-small-printed'\n",
    ").to(device)\n",
    "\n",
    "\n",
    "eval_new_data(\n",
    "    data_path=os.path('1.jpg'),\n",
    "    num_samples=1,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTrOcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure correct environment in jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure DTrOCr installation is within scope of notebooko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting Pillow==10.4.0\n",
      "  Using cached pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting torch==2.3.1\n",
      "  Using cached torch-2.3.1-cp39-cp39-win_amd64.whl (159.7 MB)\n",
      "Collecting transformers==4.42.4\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (3.6.0)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (0.25.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (1.21.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (0.4.5)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (21.3)\n",
      "Collecting intel-openmp==2021.*\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.*\n",
      "  Using cached tbb-2021.13.1-py3-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.42.4->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 3)) (2022.9.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1->-r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt (line 2)) (1.2.1)\n",
      "Installing collected packages: tbb, intel-openmp, Pillow, mkl, torch, tokenizers, transformers\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR\\requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Lenovo\\Documents\\GitHub\\Elec376_F24_group7\\backend\\ml\\DTrOCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtrocr.config import DTrOCRConfig\n",
    "from dtrocr.model import DTrOCRLMHeadModel\n",
    "from dtrocr.processor import DTrOCRProcessor\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "config = DTrOCRConfig()\n",
    "model = DTrOCRLMHeadModel(config)\n",
    "processor = DTrOCRProcessor(DTrOCRConfig())\n",
    "\n",
    "model.eval()        # set model to evaluation mode for deterministic behaviour\n",
    "path_to_image = \"1.jpg\"  # path to image file\n",
    "\n",
    "inputs = processor(\n",
    "    images=Image.open(path_to_image).convert('RGB'),\n",
    "    texts=processor.tokeniser.bos_token,\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.generate(\n",
    "    inputs=inputs, \n",
    "    processor=processor, \n",
    "    num_beams=3,    # defaults to 1 if not specified\n",
    "    use_cache=True  # defaults to True if not specified\n",
    ")\n",
    "\n",
    "predicted_text = processor.tokeniser.decode(model_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BringingUnix Bringing targ targ PAN targ billed targ targ targ targ targ PAN targ targ targ targvez PAN targ targ targUnix critic targ frustrationvez ANY targvez targ targ targ targ targ targ histories billed targ targ targ critic targvez targarton targ targ targ targ targ astounding targ155 targ next targ targ targ Jennings targ targ PAN targvez PAN targ critic billed targUnix targ targvez Bringing targ histories criticvez targ targ targincinnati targ targ targ Universities compan155 targ critic targ targ targ enclosed Bringing targ enclosed targ targ targ targ collected targ targ critic targ targ targ PAN Jennings targvez PAN targ targ PAN targ targ targ targ targ targ targ enclosed targ\n"
     ]
    }
   ],
   "source": [
    "print(predicted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
